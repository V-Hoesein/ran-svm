{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sumpah ya Avoskin cica mugwort gue pKe malah j...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Selama ini base makeupnya wardah kayak susah b...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ka Lip itu lipstik yg dipegang waktu akhir2 pa...</td>\n",
       "      <td>negatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>salah satu produk lokal ter luv yg aku punya! ...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Waw Kaka kulit nya bagus bgt pake sabun mandi ...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Asalamualaikumyasalam emuah.cantiknya tasya fa...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment    label\n",
       "0  Sumpah ya Avoskin cica mugwort gue pKe malah j...  negatif\n",
       "1  Selama ini base makeupnya wardah kayak susah b...  negatif\n",
       "2  Ka Lip itu lipstik yg dipegang waktu akhir2 pa...  negatif\n",
       "3  salah satu produk lokal ter luv yg aku punya! ...  positif\n",
       "4  Waw Kaka kulit nya bagus bgt pake sabun mandi ...  positif\n",
       "5  Asalamualaikumyasalam emuah.cantiknya tasya fa...  positif"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "dataset_path = os.path.realpath(os.path.join(os.path.dirname(__name__), '..', 'app','static','uploads', 'dataset.csv'))\n",
    "df_comments = pd.read_csv(dataset_path)\n",
    "df_comments.tail(n=99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "negatif    3\n",
       "positif    3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melihat jumlah data\n",
    "df_comments['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "stopword_factory = StopWordRemoverFactory()\n",
    "combined_stopwords = set(stopword_factory.get_stop_words()).union(set(stopwords.words('english')))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = clean_text(text).lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in combined_stopwords]\n",
    "    stemmed = [stemmer.stem(word) for word in tokens]\n",
    "    return ' '.join(stemmed)\n",
    "\n",
    "\n",
    "df_comments['preprocess'] = df_comments['comment'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform TF data Test dengan data Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    negatif\n",
      "1    negatif\n",
      "2    negatif\n",
      "3    positif\n",
      "4    positif\n",
      "5    positif\n",
      "Name: label, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(df_comments['preprocess'])\n",
    "y_train = df_comments['label']\n",
    "\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "idf_values = vectorizer.idf_\n",
    "\n",
    "print(y_train) # cetak label data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Function to compute raw TF (counts of terms in document)\n",
    "def compute_raw_tf(doc):\n",
    "    words = doc.split()\n",
    "    count = Counter(words)\n",
    "    return count\n",
    "\n",
    "# Compute normalized TF\n",
    "def compute_tf(doc):\n",
    "    words = doc.split()\n",
    "    count = Counter(words)\n",
    "    total_terms = len(words)\n",
    "    tf = {term: count[term] / total_terms for term in count}\n",
    "    return tf\n",
    "\n",
    "# Create DataFrame for TF-IDF\n",
    "tfidf_df = pd.DataFrame(X_train.toarray().T, index=terms, columns=[f'D{i+1}' for i in range(len(df_comments['preprocess']))])\n",
    "idf_df = pd.DataFrame(idf_values, index=terms, columns=[\"IDF\"])\n",
    "\n",
    "# Compute raw TF for each document (term count)\n",
    "raw_tf_dicts = [compute_raw_tf(doc) for doc in df_comments['preprocess']]\n",
    "raw_tf_df = pd.DataFrame(raw_tf_dicts, index=[f'D{i+1}' for i in range(len(df_comments['preprocess']))]).T\n",
    "\n",
    "\n",
    "# Compute normalized TF for each document\n",
    "tf_dicts = [compute_tf(doc) for doc in df_comments['preprocess']]\n",
    "tf_df = pd.DataFrame(tf_dicts, index=[f'D{i+1}' for i in range(len(df_comments['preprocess']))]).T\n",
    "\n",
    "# Fill NaN values with 0\n",
    "raw_tf_df = raw_tf_df.fillna(0)\n",
    "tf_df = tf_df.fillna(0)\n",
    "idf_df = idf_df.fillna(0)\n",
    "tfidf_df = tfidf_df.fillna(0)\n",
    "\n",
    "# Sum all normalized TF values across all documents (TFNormAll)\n",
    "tf_norm_all = tf_df.sum(axis=1)\n",
    "\n",
    "# Compute Document Frequency (DF) - number of documents where the term appears\n",
    "df_values = (raw_tf_df > 0).sum(axis=1)\n",
    "\n",
    "# Create final DataFrame\n",
    "final_df = pd.DataFrame(index=terms)\n",
    "final_df['Terms'] = terms\n",
    "\n",
    "# Add raw TF for each document (Raw Terms per document)\n",
    "final_df = final_df.join(raw_tf_df.add_prefix('TF'))  # Add raw term counts for each document\n",
    "\n",
    "# Add normalized TF for each document\n",
    "final_df = final_df.join(tf_df.add_prefix('TFN'))  # Add normalized TF for each document\n",
    "\n",
    "# Add sum of normalized TFs across all documents\n",
    "final_df['TFNAll'] = tf_norm_all\n",
    "\n",
    "# Add Document Frequency (DF) column\n",
    "final_df['DF'] = df_values\n",
    "\n",
    "# Add IDF column\n",
    "final_df['IDF'] = idf_df['IDF']\n",
    "\n",
    "# Add TF-IDF for each document\n",
    "final_df = final_df.join(tfidf_df.add_prefix('TFIDF_'))\n",
    "\n",
    "# Round all numeric columns to 3 decimal places\n",
    "final_df = final_df.round(3)\n",
    "\n",
    "# Export the final DataFrame to CSV\n",
    "final_df.to_csv('train_metrics.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latih Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\000-Python-Project\\ran-svm\\notebook\\trained_model.pkl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "result_path = result_path = os.getcwd()\n",
    "model_file = os.path.join(result_path, 'trained_model.pkl')\n",
    "\n",
    "if os.path.exists(model_file):\n",
    "    model = joblib.load(model_file)\n",
    "else:\n",
    "    model = SVC(random_state=0, kernel='linear')\n",
    "    model.fit(X_train, y_train)\n",
    "    joblib.dump(model, model_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediksi Kelas Comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negatif']\n"
     ]
    }
   ],
   "source": [
    "new_comment = 'sudah banget nempel di muka' # text train\n",
    "X_test = preprocess_text(new_comment)\n",
    "\n",
    "X_test = vectorizer.transform([X_test])\n",
    "predict = model.predict(X_test)\n",
    "print(predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
